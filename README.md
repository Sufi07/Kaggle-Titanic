
# Kaggle Titanic Project

In this Project, the goal is to correctly predict if someone survived the Titanic shipwreck. 

## Project Walk Through
https://www.youtube.com/watch?v=I3FBJdiExcg

### Best results : 77.751% accuracy (Top 33%)
## Overview
1) Understand the shape of the data (Histograms, box plots, etc.)
2) Data Cleaning
3) Data Exploration
4) Feature Engineering
5) Data Preprocessing for Model
6) Basic Model Building
7) Model Tuning
8) Ensemble Modle Building
9) Results


## Models: XGBoost

Here we choose the eXtremely famous library for boosted tree learning model, XGBoost. It was built to optimize large-scale boosted tree algorithms. For further information about the algorithm, check out the official documentation.
https://xgboost.readthedocs.io/en/latest/
